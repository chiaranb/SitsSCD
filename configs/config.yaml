defaults:
  - model: baseline
  - computer: gpu
  - dataset: muds
  - _self_

model:
  output_dir: outputs/
  dataset: ${dataset}

  val_metrics:
    _target_: metrics.scd_metrics.SCDMetric
    num_classes: ${dataset.num_classes}
    class_names: ${dataset.class_names}
    ignore_index: ${dataset.ignore_index}

  test_metrics:
    _target_: metrics.scd_metrics.SCDMetric
    num_classes: ${dataset.num_classes}
    class_names: ${dataset.class_names}
    ignore_index: ${dataset.ignore_index}
  
  logging:
    train_image_interval: 10
    val_image_interval: 1

datamodule:
  _target_: data.datamodule.ImageDataModule
  domain_shift_type: ${domain_shift_type}   
  train_dataset: ${dataset.train_dataset}
  val_dataset_out: ${dataset.val_dataset_out}
  val_dataset_temporal: ${dataset.val_dataset_temporal}
  val_dataset_in: ${dataset.val_dataset_in}
  test_dataset_out: ${dataset.test_dataset_out}
  test_dataset_temporal: ${dataset.test_dataset_temporal}
  test_dataset_in: ${dataset.test_dataset_in}
  global_batch_size: ${dataset.global_batch_size}
  num_workers: ${computer.num_workers}
  num_nodes: ${computer.num_nodes}
  num_devices: ${computer.devices}

trainer:
  _target_: pytorch_lightning.Trainer
  devices: ${computer.devices}
  accelerator: ${computer.accelerator}
  strategy: ${computer.strategy}
  num_nodes: ${computer.num_nodes}
  precision: ${computer.precision}
  max_epochs: 50
  check_val_every_n_epoch: 5
  num_sanity_val_steps: 0

eval:
  checkpoint_path: null

logger:
  _target_: pytorch_lightning.loggers.WandbLogger
  name: ${experiment_name}
  project: test
  log_model: True
  offline: False
  entity: chiaranguyenba-politecnico-di-milano

checkpoints:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: ${root_dir}/checkpoints/${experiment_name}
  filename: 'best_miou_ckpt'
  monitor: val/miou
  save_last: True
  save_top_k: 1
  every_n_epochs: 1
  mode: max
  enable_version_counter: False

checkpoints_all:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: ${root_dir}/checkpoints/${experiment_name}/all_epochs
  filename: 'epoch_{epoch:02d}_ckpt'
  save_top_k: -1
  every_n_epochs: 1
  save_on_train_epoch_end: True
  monitor: null

early_stopping:
  _target_: pytorch_lightning.callbacks.EarlyStopping
  monitor: val/miou
  min_delta: 0.0
  patience: 5
  mode: max
  check_finite: True
  
progress_bar:
  _target_: pytorch_lightning.callbacks.TQDMProgressBar
  refresh_rate: ${computer.progress_bar_refresh_rate}

data_dir: ${root_dir}/datasets
root_dir: ${hydra:runtime.cwd}
experiment_name: ${dataset.name}_${model.name}
mode: train
domain_shift_type: none   # domain shift type: none, spatial, temporal
num_classes: ${dataset.num_classes}

hydra:
  run:
    dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}/${experiment_name}
  job:
    chdir: true